version: '3.8'

services:
  api:
    build: .
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - MAX_QUEUE_LENGTH=100
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    command: sh -c "apt-get update && apt-get install -y curl && ollama serve"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_ORIGINS=*
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - app-network
    # This healthcheck ensures Ollama is ready before API starts
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  init-ollama:
    image: curlimages/curl:latest
    command: |
      sh -c '
      echo "Waiting for Ollama to be ready..."
      until curl -s -f "http://ollama:11434/api/tags" > /dev/null 2>&1; do
        sleep 2
      done
      echo "Ollama is ready"
      echo "Pulling Gemma 1B model..."
      curl -X POST http://ollama:11434/api/pull -d "{\"name\": \"gemma3:1b\"}"
      echo "Setup complete!"
      '
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - app-network

volumes:
  ollama_data:
    driver: local

networks:
  app-network:
    driver: bridge
